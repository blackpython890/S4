{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S5-Assignment-File2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgpT80A4iZHWDxWsmLveYJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagatabhay/S4/blob/master/S5_Assignment_File2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMU-hsxWB_VX",
        "colab_type": "code",
        "outputId": "6f64c889-b62c-477e-fa12-e80f13e9ef93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "train_transforms = transforms.Compose([ transforms.ToTensor(), \n",
        "                                        transforms.Normalize((0.1307,) , (0.3081,))])\n",
        "\n",
        "test_transforms = transforms.Compose([ transforms.ToTensor(), \n",
        "                                      transforms.Normalize((0.1307,),(0.3081,))])\n",
        "\n",
        "train = datasets.MNIST('./data',\n",
        "                        train = True , \n",
        "                        download = True , \n",
        "                        transform = train_transforms )\n",
        "\n",
        "test = datasets.MNIST('./data', \n",
        "                       train = False , \n",
        "                       download = True , \n",
        "                       transform = test_transforms )\n",
        "\n",
        "\n",
        "seed = 1\n",
        "torch.manual_seed(seed)\n",
        "print(torch.manual_seed(seed))\n",
        "\n",
        "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
        "print(\"Device : \", device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch._C.Generator object at 0x7fb306f67330>\n",
            "Device :  cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojdhr2sxD4Fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train , \n",
        "                                           batch_size = batch_size , \n",
        "                                           shuffle = True , \n",
        "                                           pin_memory = True , \n",
        "                                           num_workers = 1 )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test ,\n",
        "                                          batch_size = batch_size ,\n",
        "                                          shuffle = True ,\n",
        "                                          pin_memory = True ,\n",
        "                                          num_workers = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7STui0QD67L",
        "colab_type": "code",
        "outputId": "01728f45-2b46-478b-d8b9-f774ef2dd6f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_data = train.train_data\n",
        "#print(\"Train Data 1 : \", train_data)\n",
        "\n",
        "train_data = train.transform( train_data.numpy() )\n",
        "#print(\"Train Data 2 : \",train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAlyxrFXD-OA",
        "colab_type": "code",
        "outputId": "5ab2ac7f-515f-49ce-eade-7c1133310469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print(\" -Numpy Shape   : \" , train.train_data.cpu().numpy().shape )\n",
        "print(\" -Tensor Shape  : \" , train.train_data.size() )\n",
        "print(\" -Minimum       : \" , torch.min(train_data) )\n",
        "print(\" -Maximun       : \" , torch.max(train_data) )\n",
        "print(\" -Mean          : \" , torch.mean(train_data) )\n",
        "print(\" -Varian        : \" , torch.var(train_data) )\n",
        "print(\" -STD Deviation : \" , torch.std(train_data) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [ Data Stats and View ] \n",
            " -Numpy Shape   :  (60000, 28, 28)\n",
            " -Tensor Shape  :  torch.Size([60000, 28, 28])\n",
            " -Minimum       :  tensor(-0.4242)\n",
            " -Maximun       :  tensor(2.8215)\n",
            " -Mean          :  tensor(0.0009)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " -Varian        :  tensor(1.0001)\n",
            " -STD Deviation :  tensor(1.0000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MopPhRCED_B1",
        "colab_type": "code",
        "outputId": "0d897966-6847-4917-a8a3-8f2eb57f26f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "images , labels = dataiter.next()\n",
        "\n",
        "print(\"Image Shape  : \" , images.shape )\n",
        "print(\"Labels Shape : \" , labels.shape )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Shape  :  torch.Size([100, 1, 28, 28])\n",
            "Labels Shape :  torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys1b8d_tEKS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def _init_(self):\n",
        "        super(Net, self)._init_()\n",
        "        #self.conv1 = nn.Conv2d(1, 32, 3, padding=1) #input -? OUtput? RF\n",
        "        #self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        #self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        #self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        #self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        #self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        #self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "        #self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "        #self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1,out_channels=10,kernel_size=(3,3),padding=0), #26\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.BatchNorm2d(num_features=10),\n",
        "                                   #nn.Dropout(0.1)\n",
        "                                   )\n",
        "\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=10,out_channels=16,kernel_size=(3,3),padding=0), #24\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.BatchNorm2d(num_features=16),\n",
        "                                   #nn.Dropout(0.1)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=16,out_channels=20,kernel_size=(3,3),padding=0), #22\n",
        "                                   nn.BatchNorm2d(num_features=20),\n",
        "                                   #nn.Dropout(0.1)\n",
        "                                   )                          \n",
        "        \n",
        "        self.pool1 =  nn.MaxPool2d(2,2)\n",
        "         \n",
        "        \n",
        "        \n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(in_channels=20,out_channels=10,kernel_size=(1,1),padding=0), #11\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.BatchNorm2d(num_features=10),\n",
        "                                   nn.Dropout(0.1)\n",
        "                                   ) \n",
        "        \n",
        "        #self.pool2 =  nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.conv5 = nn.Sequential(nn.Conv2d(in_channels=10,out_channels=20,kernel_size=(3,3),padding=0), #9\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.BatchNorm2d(num_features=20),\n",
        "                                   #nn.Dropout(0.1)\n",
        "                                   ) \n",
        "        \n",
        "        self.conv6 = nn.Sequential(nn.Conv2d(in_channels=20,out_channels=16,kernel_size=(3,3),padding=0), #7\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.BatchNorm2d(num_features=16),\n",
        "                                   #nn.Dropout(0.1)\n",
        "                                   ) \n",
        "        self.conv7 = nn.Sequential(nn.Conv2d(in_channels=16,out_channels=10,kernel_size=(1,1),padding=0) #5\n",
        "                                   #nn.ReLU()\n",
        "                                   #nn.BatchNorm2d(num_features=10)\n",
        "                                   #nn.DroupOut2d()\n",
        "                                   )\n",
        "        self.gap  =  nn.Sequential(nn.AvgPool2d(kernel_size=7)) \n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "              \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        #x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "        #x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "        #x = F.relu(self.conv7(x))\n",
        "        #x = x.view(-1, 10)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv4(x)\n",
        "        #x = self.pool2(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        \n",
        "        x = self.conv7(x)\n",
        "        x = self.gap(x)\n",
        "        \n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5h1KWZZLI9-",
        "colab_type": "code",
        "outputId": "46ced275-1092-4ea2-db3b-00227b0fc19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-83d94dfc5ea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-2b98f0215799>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m#x = F.relu(self.conv7(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m#x = x.view(-1, 10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'conv1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RasIgsMVHOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)                        # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyHF82E3YCyH",
        "colab_type": "code",
        "outputId": "621d69a4-3aa3-40f2-ad49-3294ed28cf12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1,9):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    print(\"Iteration No : \",epoch)\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/600 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "loss=0.16490314900875092 batch_id=599: 100%|██████████| 600/600 [00:18<00:00, 32.77it/s]\n",
            "  0%|          | 0/600 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0902, Accuracy: 9768/10000 (97.68%)\n",
            "\n",
            "Iteration No :  1\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.05752793326973915 batch_id=599: 100%|██████████| 600/600 [00:18<00:00, 32.77it/s]\n",
            "  0%|          | 0/600 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0551, Accuracy: 9837/10000 (98.37%)\n",
            "\n",
            "Iteration No :  2\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.08524485677480698 batch_id=599: 100%|██████████| 600/600 [00:18<00:00, 32.36it/s]\n",
            "  0%|          | 0/600 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0436, Accuracy: 9868/10000 (98.68%)\n",
            "\n",
            "Iteration No :  3\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.02991282008588314 batch_id=599: 100%|██████████| 600/600 [00:18<00:00, 32.85it/s]\n",
            "  0%|          | 0/600 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0414, Accuracy: 9875/10000 (98.75%)\n",
            "\n",
            "Iteration No :  4\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.05463947355747223 batch_id=599: 100%|██████████| 600/600 [00:18<00:00, 32.30it/s]\n",
            "  0%|          | 0/600 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0366, Accuracy: 9881/10000 (98.81%)\n",
            "\n",
            "Iteration No :  5\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.05065556988120079 batch_id=599: 100%|██████████| 600/600 [00:18<00:00, 31.61it/s]\n",
            "  0%|          | 0/600 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0298, Accuracy: 9901/10000 (99.01%)\n",
            "\n",
            "Iteration No :  6\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.026856709271669388 batch_id=599: 100%|██████████| 600/600 [00:18<00:00, 33.08it/s]\n",
            "  0%|          | 0/600 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0348, Accuracy: 9905/10000 (99.05%)\n",
            "\n",
            "Iteration No :  7\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.009450649842619896 batch_id=599: 100%|██████████| 600/600 [00:18<00:00, 32.09it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0340, Accuracy: 9899/10000 (98.99%)\n",
            "\n",
            "Iteration No :  8\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayw1FIssGHeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}